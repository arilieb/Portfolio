{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0660e087fbf79003cb270353f75560f2",
     "grade": false,
     "grade_id": "cell-7b1a79c8761504a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 5: Anomaly Detection with Negative Selection\n",
    "\n",
    "### Assignment description:\n",
    "\n",
    "In this assignment, you will use the same Textor algorithm from the previous assignment to detect anomalies in a different data set. We will use a fetal monitoring dataset (known as a cardiotocography) from the UC Irvine Machine Learning Repository. \n",
    "\n",
    "### Assignment goals:\n",
    "\n",
    "1. Apply the Textor algorithm to a practical example\n",
    "2. Use ROC analysis to score the detector\n",
    "\n",
    "### Assignment question overview:\n",
    "\n",
    "1. Write a function to process the cardiotocography data set. [Question 1](#question1)\n",
    "2. Paste any previous functions or write additional helper functions (not-graded). [Question 2](#question2)\n",
    "3. Write a function to calculate AUC values over an interval of $r$ values. [Question 3](#question3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05c143efc72a1bf7121918027fe2738f",
     "grade": false,
     "grade_id": "cell-38c1e22c8214b2a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Cardiotocography Dataset\n",
    "\n",
    "A cardiotocography is a technical way to measure the fetal heart rate (FHR) and the uterine contractions (UC) during pregnancy. Obstetricians then classify these readings as either normal, suspect, and pathologic. Figure 1 shows the display of a cardiotocograph (CTG), the FHR is shown in orange and the UC is shown in green. Figure 2 shows the output of a typical CTG where the line labeled **A** is the FHR and the line labeled **D** is the UC. More details on the data set are here: http://odds.cs.stonybrook.edu/cardiotocogrpahy-dataset/. \n",
    "\n",
    "The data consists of 21 real-valued variables, outliers and inliers. Each row is a sample, each column is an observed variable , and the training file includes the ground truth labels of the samples. The data are in: ``cardio_train.csv`` and ``cardio_test.csv``. \n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/cardio.jpg\" width=\"250\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 1: Cardiotocograph display</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"images/CTG_Output.jpg\" width=\"650\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 2: Cardiotocograph output</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "*Image sources: Wikipedia*\n",
    "\n",
    "\n",
    "\n",
    "## Data Processing\n",
    "\n",
    "In order for the continuous data to work well with the negative selection algorithm, we will need to bin the values into categorical variables. For consistency across assignments, we will simply bin each of the variables in to 10 bins. This will produce strings of length 21 symbols and an alphabet size of 10 characters (e.g. A indicates the lowest category and J indicates the highest). \n",
    "\n",
    "Next, we will need to format the data in such a way that the new train and test data may be read directly by Textor's algorithm used in the previous assignment. Recall that both the train and the test data for the languages were ``.csv`` files with one string of length 10 per line. Here, we would like there to be one string of length 21 per line. These strings will correspond to the 21 variables in a row of either ``cardio_train.csv`` or ``cardio_test.csv``. \n",
    "\n",
    "### Creating Bins with pandas\n",
    "\n",
    "To avoid ambiguity in how the data can be binned, we suggest that you use the ``cut`` function from pandas. Note that this function allows for a labels parameter to be passed. To map our binned data to characters we can define the labels array as follows:\n",
    "\n",
    "``labels=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']``.\n",
    "\n",
    "After defining labels we can call ``pandas.cut(x, bins=10, labels)``, where ``x`` is the data column.\n",
    "\n",
    "<a id='question1'></a>\n",
    "## Question 1:\n",
    "\n",
    "Write the function ``process_data(file)`` which processes either ``cardio_train.csv`` or ``cardio_test.csv`` into the format specified in the \"Data Processing\" section. This function returns the string ``processed_file`` which is a path to the final processed file. This function will not be directly graded, but will be used in the grading of later questions. The processed file should be in ``.csv`` format with one string of length 21 per row. The final processed file should look similar to the strings below. \n",
    "\n",
    "**Do not include headers or indices in your final processed file. The file should contain only strings.**\n",
    "\n",
    "```\n",
    "EEDAECEAACACIBJDBEDDA\n",
    "EEBAFCEAACACIBJCBEDDA\n",
    "EEBAFBEAADAEHAFGAEDDA\n",
    "EEDAFAEAADADHAFFAEDDA\n",
    "EECBFBEACBACDDDCAEDDA\n",
    "EEEEEAEACBABFBEBAEDEA\n",
    "DDDICDECBCABGBGDAFCDE\n",
    "DDCHCCEEBCABGBGBAECDC\n",
    "DDDJDCEABCACIAHCAFCDD\n",
    "DDBJDCEFBCABGAEDADCCC\n",
    "DDCJDCEDCBABHBGDBDCDB\n",
    "DDCICCEFCBABJAJFADCCB\n",
    "EEACAHEACIAAJAJFADAAF\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e21466847811d719df258db740d5aa72",
     "grade": false,
     "grade_id": "cell-98fab61b6abc9346",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'formatted_cardio_test.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def process_data(file):\n",
    "    labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "    df = pd.read_csv(file, skiprows=1, header = None, index_col = False)\n",
    "#     print(df)\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    if file == 'cardio_test.csv':\n",
    "        df.drop(df.columns[-1], axis=1, inplace=True)\n",
    "#     print(df)\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.cut(df[col], bins=10, labels=labels)\n",
    "    \n",
    "    \n",
    "    string_output = ''\n",
    "    for index, row in df.iterrows():\n",
    "        string_output += ''.join(row) + '\\n'\n",
    "#     print(string_output)\n",
    "    lines = string_output.split('\\n')\n",
    "\n",
    "    with open('formatted_' + file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        for line in lines:\n",
    "            csvwriter.writerow(line.split())\n",
    "    \n",
    "    '''\n",
    "    Function to process the data in a given file. \n",
    "    Inputs:\n",
    "        file: path to either test or train file\n",
    "    Outputs:\n",
    "        processed_file: path to processed version of the file\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return 'formatted_' + file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e2ec9dd599dbf0b34218960c63b5e4b",
     "grade": false,
     "grade_id": "cell-a03ce1766d2a397b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementing Negative Selection Recap\n",
    "\n",
    "Recall from the previous assignment that we used a python subprocess to use Textor's ``negsel.jar`` file. To start a subprocess, we will first need to import the ``subprocess`` module and the ``run`` and ``PIPE`` submodules. Then, we will need to run the process with an array of arguments and the opened input file. We will use the Textor example ([here](http://johannes-textor.name/negativeselection.html)) to demonstrate how subprocesses work.\n",
    "\n",
    "The following command trains the negative selection algorithm on the ``english.train`` data set and tests on the ``hiligaynon.test`` data set from the previous assignment.\n",
    "\n",
    "``java -jar negsel.jar -c -n 10 -r 4 -self english.train < hiligaynon.test ``\n",
    "\n",
    "In this assignment, you will used the processed train and test data to run this same command. Recall that to run this subprocess, we will need to first build an argument list from the command. This allows the subprocess command to parse the command and flags. Using the command given above, we will construct the following argument list. \n",
    "\n",
    "``args = ['java', '-jar', 'negsel.jar', '-c', '-n', '10', '-r','4', '-self', 'negsel_src/tests/english.train']``\n",
    "\n",
    "Next, we will need to open the test file to read from. This step is necessary as the argument list will not recognize the redirection from stdin (``< hiligaynon.test``).\n",
    "\n",
    "``input_file = open('negsel_src/tests/hiligaynon.test', 'r')``\n",
    "\n",
    "Finally, we can use the ``run`` submodule to call the command and pipe the output. \n",
    "\n",
    "``result = run(args, stdout=PIPE, stdin=input_file, universal_newlines=True)``\n",
    "\n",
    "The final results will be stored in ``result.stdout``. This can be saved and parsed later as needed. \n",
    "\n",
    "Refer to the previous assignment for more information on how to run the code as well as a full running example.\n",
    "\n",
    "**REMEMBER TO ADJUST THE STRING LENGTH FOR THIS ASSIGNMENT.**\n",
    "\n",
    "## Exploring Model Parameterization\n",
    "\n",
    "In the previous assignment, we used $r=4$ contiguous bits for all of our testing. However, this does not ensure optimal anomaly detection. In this assignment, we will investigate the tuning of the $r$ parameter for the *$r$-contiguous* patterns. \n",
    " \n",
    "\n",
    "### $r$-contiguous Patterns\n",
    "\n",
    "Textor in _\"A Comparative Study of Negative Selection Based Anomaly Detection in Sequence Data\"_ defines the $r$-contiguous pattern as follows.\n",
    "\n",
    "<blockquote>An $r$-contiguous pattern is a string $d\\in \\Sigma^l$. It matches another string $s\\in  \\Sigma^l$ if $d$ and $s$ are identical in at least $r$ contiguous positions, i.e., if there is an $i\\in \\{1,...,l-r+1\\}$ such that the substrings of length $r$ of $s$ and $d$ starting at the $i$-th position are equal. </blockquote> \n",
    "\n",
    "### Scoring the Detector \n",
    "\n",
    "Since our strings are of length 21, we will consider $r\\in [2,10]$. For simplicity, we will use the *AUC* as described in the previous assignment. Recall that the ROC curve is created by plotting the false positive (FP) rate and the true positive (TP) rate over an interval of values of $\\theta$. Generally, a meaningful classifier has an area under the curve (AUC) value greater than 0.5, and a AUC value close to 1 signifies a near-perfect classifier. \n",
    "\n",
    "You may use the ``fp_tp_calc(file, theta)`` and ``auc_calc(file)`` functions from the previous assignment to calculate the AUC values. Additionally, we will let $\\theta \\in [0,10]$, and $ \\theta \\in \\mathbb{Z}$. \n",
    "\n",
    "<a id='question2'></a>\n",
    "## Question 2: Using previous functions\n",
    "\n",
    "Use the answer box below to paste in any functions that you would like to use for Question 2. You may also use this area to write any additional helper functions and/or edit your old functions to generalize to this problem and dataset (i.e., by adding a new parameter to handle the fact that r is an additional input variable). Labels for this dataset may be found in the file cardio.labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d46e8b81392c48ef0da66900f86331d",
     "grade": false,
     "grade_id": "cell-74e05cd0931201b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## PASTE ANY FUNCTIONS YOU WOULD LIKE TO USE HERE\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from subprocess import run, PIPE\n",
    "from sklearn import metrics\n",
    "\n",
    "def fp_tp_calc(file, theta, r):\n",
    "    '''\n",
    "    Function to calculate the false positive and true positive rate for a given test set and value of theta.\n",
    "    Inputs: \n",
    "        file: path to the test file\n",
    "        theta: threshold value for ROC analysis\n",
    "    Output:\n",
    "        fp_tp : python tuple of the FPR and TPR given by (fp, tp)\n",
    "    '''\n",
    "    \n",
    "    args = ['java', '-jar', 'negsel.jar','-n','21', '-r', str(r), '-self', 'formatted_cardio_train.csv']\n",
    "    with open(file, 'r') as input_file:\n",
    "        result = run(args, stdout=PIPE, stderr=PIPE, stdin=input_file, universal_newlines=True)\n",
    "    anomaly_scores = result.stdout.splitlines()\n",
    "#     print(anomaly_scores)\n",
    "    anomaly_scores = [float(score) for score in anomaly_scores]\n",
    "    with open('cardio.labels', 'r') as f:\n",
    "        labels = np.array([int(label) for label in f.read().splitlines()])\n",
    "    normal_scores = [score for score, label in zip(anomaly_scores, labels) if label == 0]\n",
    "    anomalous_scores = [score for score, label in zip(anomaly_scores, labels) if label == 1]\n",
    "    \n",
    "    false_positives = sum(score>theta for score in normal_scores)\n",
    "    true_positives = sum(score>theta for score in anomalous_scores)\n",
    "    fpr = false_positives / labels.tolist().count(0)\n",
    "    tpr = true_positives / labels.tolist().count(1)\n",
    "    fp_tp = (fpr, tpr)\n",
    "    # your code here\n",
    "    \n",
    "    return fp_tp\n",
    "\n",
    "def auc_calc(file, r):\n",
    "    '''\n",
    "    Function to calculate the AUC for a given test set over the theta interval of [0,10].\n",
    "    Inputs: \n",
    "        file: path to the test file\n",
    "    Output:\n",
    "        auc : area under the curve for the ROC curve of the test set\n",
    "    '''\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    for theta in range(11):\n",
    "#         print(theta)\n",
    "        fp,tp = fp_tp_calc(file, theta, r)\n",
    "        fprs.append(fp)\n",
    "        tprs.append(tp)\n",
    "    auc = metrics.auc(fprs, tprs)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "\n",
    "    return auc\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25c517e2d13bd817162ea5375b399438",
     "grade": false,
     "grade_id": "cell-ab91cec18db1a1a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='question3'></a>\n",
    "## Question 3:\n",
    "\n",
    "Write the function ``r_auc_tuple(file)`` that calculates a list of tuples for each value of $r\\in [2,10]$ over $\\theta \\in [0,10]$ for a given test file. This will result in a list of 10 tuples where the first element in each tuple is the value of $r$ and the second element is the AUC value.  This list will be returned as ``tuples_list`` and will be graded based on accuracy. The labels for the test file are in ``cardio.labels``.\n",
    "\n",
    "For reference, the following command should return the AUC value for $r=2$: ``r_auc_tuple('cardio_test.csv')[0][1]``.\n",
    "\n",
    "**Remember to use the ``process_data(file)`` function to run the Textor algorithm with the correct files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7113eee44feb422baef6e2fcb413bd87",
     "grade": false,
     "grade_id": "cell-cbc7d8667ab1cdd7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def r_auc_tuple(file):\n",
    "    use_file = process_data(file)\n",
    "    process_data('cardio_train.csv')\n",
    "\n",
    "    \n",
    "    tuples_list = []\n",
    "    \n",
    "    for r in range(2,11):\n",
    "        tuples_list.append((r, auc_calc(use_file, r)))\n",
    "\n",
    "        \n",
    "    '''\n",
    "    Function to compute the auc values for various values of r.\n",
    "    Inputs: \n",
    "        file: path to the test file\n",
    "    Outputs:\n",
    "        tuples_list: a list of tuples where the first value in each tuple is r and the second value is the auc\n",
    "    '''\n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return tuples_list\n",
    "# tuples = r_auc_tuple('cardio_test.csv')\n",
    "# print(tuples)\n",
    "# print(type(tuples))\n",
    "# assert len(tuples) == 9\n",
    "# assert round(tuples[0][1],2) == 0.75\n",
    "# assert round(tuples[7][1],2) == 0.0\n",
    "# print(\"All test cases passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5db892b28acf35248952a559852c880d",
     "grade": false,
     "grade_id": "cell-338a0bdd6b691c81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.7548143650242887), (3, 0.7168459403192228), (4, 0.2917071478140181), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0)]\n",
      "All test cases passed\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Check the output of your functions.\n",
    "'''\n",
    "tuples = r_auc_tuple('cardio_test.csv')\n",
    "print(tuples)\n",
    "assert len(tuples) == 9\n",
    "assert round(tuples[0][1],2) == 0.75\n",
    "assert round(tuples[7][1],2) == 0.0\n",
    "print(\"All test cases passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6dea6e17deb3fa09a12017922701413",
     "grade": true,
     "grade_id": "cell-440a3463d699e6f3",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell contains hidden tests, which are run on submission. \\nHidden test cases check the tuples for the correct AUC values using the cardio_test.tsv file.\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell contains hidden tests, which are run on submission. \n",
    "Hidden test cases check the tuples for the correct AUC values using the cardio_test.tsv file.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24383d73187ad51d4bc995a1b30bfae0",
     "grade": true,
     "grade_id": "cell-8e84de1a14be7cf5",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell contains hidden tests, which are run on submission. \n",
    "Hidden test cases check the tuples for the correct AUC values using the cardio_test.tsv file.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "684672d02379520586868002fb333d91",
     "grade": true,
     "grade_id": "cell-cf46dc1dc15d8dd1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell contains hidden tests, which are run on submission. \n",
    "Hidden test cases check the tuples for the correct AUC values using the cardio_test.tsv file.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
